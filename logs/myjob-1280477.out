JobId=1280477 JobName=garment-encoder
   UserId=pba764(5013) GroupId=ponsmoll(4037) MCS_label=N/A
   Priority=55184 Nice=0 Account=ponsmoll QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:00:01 TimeLimit=3-00:00:00 TimeMin=N/A
   SubmitTime=2025-03-28T00:57:18 EligibleTime=2025-03-28T00:57:18
   AccrueTime=2025-03-28T00:57:18
   StartTime=2025-03-28T00:57:18 EndTime=2025-03-31T01:57:18 Deadline=N/A
   PreemptEligibleTime=2025-03-28T00:58:18 PreemptTime=None
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-03-28T00:57:18 Scheduler=Main
   Partition=2080-galvani AllocNode:Sid=galvani-slurmctl:4171165
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=galvani-cn121
   BatchHost=galvani-cn121
   NumNodes=1 NumCPUs=32 NumTasks=1 CPUs/Task=32 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=32,mem=50G,node=1,billing=8,gres/gpu=1
   AllocTRES=cpu=32,mem=50G,node=1,billing=8,gres/gpu=1,gres/gpu:rtx2080ti=1
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=32 MinMemoryNode=50G MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/mnt/lustre/home/ponsmoll/pba764/projects/3DShape2VecSet/sbatch_run.sh
   WorkDir=/mnt/lustre/home/ponsmoll/pba764/projects/3DShape2VecSet
   StdErr=/mnt/lustre/home/ponsmoll/pba764/projects/3DShape2VecSet/./logs/myjob-1280477.err
   StdIn=/dev/null
   StdOut=/mnt/lustre/home/ponsmoll/pba764/projects/3DShape2VecSet/./logs/myjob-1280477.out
   Power=
   TresPerNode=gres:gpu:1
   MailUser=andrea.sanchietti@uni-tuebingen.de MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   

/home/ponsmoll/pba764/projects/3DShape2VecSet
Not using distributed mode
[00:57:30.621368] job dir: /mnt/lustre/home/ponsmoll/pba764/projects/3DShape2VecSet
[00:57:30.621513] Namespace(batch_size=64,
epochs=800,
accum_iter=1,
model='kl_garments',
point_cloud_size=2048,
clip_grad=None,
weight_decay=0.05,
lr=None,
blr=0.0001,
layer_decay=0.75,
min_lr=1e-06,
warmup_epochs=40,
data_path='../GarmentCode/garmentcodedata_v2',
output_dir='./output/',
log_dir='./output/',
device='cuda',
seed=0,
resume='',
start_epoch=0,
eval=False,
dist_eval=False,
num_workers=2,
pin_mem=False,
world_size=1,
local_rank=-1,
dist_on_itp=False,
dist_url='env://',
only_udf=False,
distributed=False)
[00:57:31.947397] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f860e784a90>
[00:57:33.067836] Model = KLAutoEncoder(
  (cross_attend_blocks): ModuleList(
    (0): PreNorm(
      (fn): Attention(
        (to_q): Linear(in_features=512, out_features=512, bias=False)
        (to_kv): Linear(in_features=512, out_features=1024, bias=False)
        (to_out): Linear(in_features=512, out_features=512, bias=True)
        (drop_path): Identity()
      )
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (norm_context): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (1): PreNorm(
      (fn): FeedForward(
        (net): Sequential(
          (0): Linear(in_features=512, out_features=4096, bias=True)
          (1): GEGLU()
          (2): Linear(in_features=2048, out_features=512, bias=True)
        )
        (drop_path): Identity()
      )
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (point_embed): PointEmbed(
    (mlp): Linear(in_features=51, out_features=512, bias=True)
  )
  (layers): ModuleList(
    (0-23): 24 x ModuleList(
      (0): PreNorm(
        (fn): Attention(
          (to_q): Linear(in_features=512, out_features=512, bias=False)
          (to_kv): Linear(in_features=512, out_features=1024, bias=False)
          (to_out): Linear(in_features=512, out_features=512, bias=True)
          (drop_path): DropPath(drop_prob=0.100)
        )
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): PreNorm(
        (fn): FeedForward(
          (net): Sequential(
            (0): Linear(in_features=512, out_features=4096, bias=True)
            (1): GEGLU()
            (2): Linear(in_features=2048, out_features=512, bias=True)
          )
          (drop_path): DropPath(drop_prob=0.100)
        )
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder_cross_attn): PreNorm(
    (fn): Attention(
      (to_q): Linear(in_features=512, out_features=512, bias=False)
      (to_kv): Linear(in_features=512, out_features=1024, bias=False)
      (to_out): Linear(in_features=512, out_features=512, bias=True)
      (drop_path): Identity()
    )
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (norm_context): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (to_outputs): Linear(in_features=512, out_features=1, bias=True)
  (proj): Linear(in_features=4096, out_features=512, bias=True)
  (mean_fc): Linear(in_features=512, out_features=4096, bias=True)
  (logvar_fc): Linear(in_features=512, out_features=4096, bias=True)
)
[00:57:33.067855] number of params (M): 112.42
[00:57:33.067866] base lr: 1.00e-04
[00:57:33.067870] actual lr: 2.50e-05
[00:57:33.067873] accumulate grad iterations: 1
[00:57:33.067876] effective batch size: 64
[00:57:33.073205] criterion = BCEWithLogitsLoss()
[00:57:33.073220] Start training for 800 epochs
[00:57:33.079378] log_dir: ./output/
